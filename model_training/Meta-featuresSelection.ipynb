{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.stack.imgur.com/g1phN.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import kurtosis, skew\n",
    "import time\n",
    "import scipy\n",
    "import sklearn\n",
    "import warnings\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_landmark_lda(X, y):\n",
    "    import sklearn.discriminant_analysis\n",
    "    if len(y.shape) == 1 or y.shape[1] == 1:\n",
    "        kf = sklearn.model_selection.KFold(n_splits=10)\n",
    "    else:\n",
    "        kf = sklearn.model_selection.KFold(n_splits=10)\n",
    "\n",
    "    accuracy = 0.\n",
    "    result=kf.split(X, y) \n",
    "    \n",
    "    try:\n",
    "        for train,test in kf.split(X,y):   \n",
    "   \n",
    "            lda = sklearn.discriminant_analysis.LinearDiscriminantAnalysis()\n",
    "\n",
    "            if len(y.shape) == 1 or y.shape[1] == 1:\n",
    "                lda.fit(X.iloc[train], y[train])\n",
    "            else:\n",
    "                lda = OneVsRestClassifier(lda)\n",
    "                lda.fit(X.iloc[train], y[train])\n",
    "\n",
    "            predictions = lda.predict(X.iloc[test])\n",
    "            accuracy += sklearn.metrics.accuracy_score(predictions, y[test])\n",
    "        return accuracy / 10\n",
    "    except scipy.linalg.LinAlgError as e:\n",
    "        print(\"LDA failed: %s Returned 0 instead!\" % e)\n",
    "        return np.NaN\n",
    "    except ValueError as e:\n",
    "        print(\"LDA failed: %s Returned 0 instead!\" % e)\n",
    "        return np.NaN\n",
    "\n",
    "\n",
    "\n",
    "def calculate_landmark_nb(X, y):\n",
    "    import sklearn.naive_bayes\n",
    "\n",
    "    if len(y.shape) == 1 or y.shape[1] == 1:\n",
    "        kf = sklearn.model_selection.KFold(n_splits=10)\n",
    "    else:\n",
    "        kf = sklearn.model_selection.KFold(n_splits=10)\n",
    "\n",
    "    accuracy = 0.\n",
    "    for train, test in kf.split(X, y):\n",
    "        nb = sklearn.naive_bayes.GaussianNB()\n",
    "\n",
    "        if len(y.shape) == 1 or y.shape[1] == 1:\n",
    "            nb.fit(X.iloc[train], y[train])\n",
    "        else:\n",
    "            nb = OneVsRestClassifier(nb)\n",
    "            nb.fit(X.iloc[train], y[train])\n",
    "\n",
    "        predictions = nb.predict(X.iloc[test])\n",
    "        accuracy += sklearn.metrics.accuracy_score(predictions, y[test])\n",
    "    return accuracy / 10\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calculate_landmark_dt(X, y):\n",
    "    import sklearn.tree\n",
    "\n",
    "    if len(y.shape) == 1 or y.shape[1] == 1:\n",
    "        kf = sklearn.model_selection.KFold(n_splits=10)\n",
    "    else:\n",
    "        kf = sklearn.model_selection.KFold(n_splits=10)\n",
    "\n",
    "    accuracy = 0.\n",
    "    for train, test in kf.split(X, y):\n",
    "        random_state = sklearn.utils.check_random_state(42)\n",
    "        tree = sklearn.tree.DecisionTreeClassifier(random_state=random_state)\n",
    "\n",
    "        if len(y.shape) == 1 or y.shape[1] == 1:\n",
    "            tree.fit(X.iloc[train], y[train])\n",
    "        else:\n",
    "            tree = OneVsRestClassifier(tree)\n",
    "            tree.fit(X.iloc[train], y[train])\n",
    "\n",
    "        predictions = tree.predict(X.iloc[test])\n",
    "        accuracy += sklearn.metrics.accuracy_score(predictions, y[test])\n",
    "    return accuracy / 10\n",
    "\n",
    "\n",
    "def calculate_landmark_dnl(X, y):\n",
    "        import sklearn.tree\n",
    "\n",
    "        if len(y.shape) == 1 or y.shape[1] == 1:\n",
    "            kf = sklearn.model_selection.KFold(n_splits=10)\n",
    "        else:\n",
    "            kf = sklearn.model_selection.KFold(n_splits=10)\n",
    "\n",
    "        accuracy = 0.\n",
    "        for train, test in kf.split(X, y):\n",
    "            random_state = sklearn.utils.check_random_state(42)\n",
    "            node = sklearn.tree.DecisionTreeClassifier(\n",
    "                criterion=\"entropy\", max_depth=1, random_state=random_state,\n",
    "                min_samples_split=2, min_samples_leaf=1,  max_features=None)\n",
    "            if len(y.shape) == 1 or y.shape[1] == 1:\n",
    "                node.fit(X.iloc[train], y[train])\n",
    "            else:\n",
    "                node = OneVsRestClassifier(node)\n",
    "                node.fit(X.iloc[train], y[train])\n",
    "            predictions = node.predict(X.iloc[test])\n",
    "            accuracy += sklearn.metrics.accuracy_score(predictions, y[test])\n",
    "        return accuracy / 10\n",
    "\n",
    "    \n",
    "\n",
    "def calculate_landmark_rnl(X, y):\n",
    "    import sklearn.tree\n",
    "\n",
    "    if len(y.shape) == 1 or y.shape[1] == 1:\n",
    "        kf = sklearn.model_selection.KFold(n_splits=10)\n",
    "    else:\n",
    "        kf = sklearn.model_selection.KFold(n_splits=10)\n",
    "    accuracy = 0.\n",
    "\n",
    "    for train, test in kf.split(X, y):\n",
    "        random_state = sklearn.utils.check_random_state(42)\n",
    "        node = sklearn.tree.DecisionTreeClassifier(criterion=\"entropy\",max_depth=1,\\\n",
    "        random_state=random_state, min_samples_split=2, min_samples_leaf=1, max_features=1)\n",
    "        node.fit(X.iloc[train], y[train])\n",
    "        predictions = node.predict(X.iloc[test])\n",
    "        accuracy += sklearn.metrics.accuracy_score(predictions, y[test])\n",
    "    return accuracy / 10\n",
    "\n",
    "\n",
    "\n",
    "def calculate_landmark_k1nn(X, y):\n",
    "    import sklearn.neighbors\n",
    "\n",
    "    if len(y.shape) == 1 or y.shape[1] == 1:\n",
    "        kf = sklearn.model_selection.KFold(n_splits=10)\n",
    "    else:\n",
    "        kf = sklearn.model_selection.KFold(n_splits=10)\n",
    "\n",
    "    accuracy = 0.\n",
    "    for train, test in kf.split(X, y):\n",
    "        kNN = sklearn.neighbors.KNeighborsClassifier(n_neighbors=1)\n",
    "        if len(y.shape) == 1 or y.shape[1] == 1:\n",
    "            kNN.fit(X.iloc[train], y[train])\n",
    "        else:\n",
    "            kNN = OneVsRestClassifier(kNN)\n",
    "            kNN.fit(X.iloc[train], y[train])\n",
    "        predictions = kNN.predict(X.iloc[test])\n",
    "        accuracy += sklearn.metrics.accuracy_score(predictions,y[test])\n",
    "    return accuracy / 10\n",
    "\n",
    "\n",
    "\n",
    "### Not a meta feature just an object\n",
    "def calculate_pca(X, y):\n",
    "    import sklearn.decomposition\n",
    "    pca = sklearn.decomposition.PCA(copy=True)\n",
    "    rs = np.random.RandomState(42)\n",
    "    indices = np.arange(X.shape[0])\n",
    "    for i in range(10):\n",
    "        try:\n",
    "            rs.shuffle(indices)\n",
    "            pca.fit(X.iloc[indices])\n",
    "            return pca\n",
    "        except LinAlgError as e:\n",
    "            pass\n",
    "    print(\"Failed to compute a Principle Component Analysis\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def calculate_PCAFractionOfComponentsFor95PercentVariance(X, y, pca):\n",
    "\n",
    "    if pca is None:\n",
    "        return np.NaN\n",
    "    sum_ = 0.\n",
    "    idx = 0\n",
    "    while sum_ < 0.95 and idx < len(pca.explained_variance_ratio_):\n",
    "        sum_ += pca.explained_variance_ratio_[idx]\n",
    "        idx += 1\n",
    "    return float(idx)/float(X.shape[1])\n",
    "\n",
    "\n",
    "def calculate_PCAKurtosisFirstPC(X, y, pca):\n",
    "    if pca is None:\n",
    "        return np.NaN\n",
    "    components = pca.components_\n",
    "    pca.components_ = components[:1]\n",
    "    transformed = pca.transform(X)\n",
    "    pca.components_ = components\n",
    "\n",
    "    kurtosis = scipy.stats.kurtosis(transformed)\n",
    "    return kurtosis[0]\n",
    "\n",
    "def calculate_PCASkewnessFirstPC(X, y, pca):\n",
    "    if pca is None:\n",
    "        return np.NaN\n",
    "    components = pca.components_\n",
    "    pca.components_ = components[:1]\n",
    "    transformed = pca.transform(X)\n",
    "    pca.components_ = components\n",
    "\n",
    "    skewness = scipy.stats.skew(transformed)\n",
    "    return skewness[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "meta_features_names=[\"nr_instances\", \"log_nr_instances\", \"nr_features\",\\\n",
    "    \"log_nr_features\", \"nr_classes\", \"nr_numerical_features\", \"nr_categorical_features\", \\\n",
    "    \"ratio_num_cat\", \"class_entropy\", \"missing_val\", \"ratio_missing_val\", \"max_prob\", \\\n",
    "    \"min_prob\", \"mean_prob\",\"std_dev\", \"dataset_ratio\", \"symbols_sum\", \"symbols_mean\", \\\n",
    "    \"symbols_std_dev\", \"skew_min\", \"skew_max\", \"skew_mean\", \"skew_std_dev\", \"kurtosis_min\",\\\n",
    "    \"kurtosis_max\", \"kurtosis_mean\", \"kurtosis_std_dev\"]\n",
    "                     #\"landmark_lda\", \"landmark_nb\",\"landmark_dt\",\\\n",
    "    #\"landmark_dnl\",\"landmark_rnl\", \"landmark_k1nn\", \"landmark_PCAFractionOfComponentsFor95PercentVariance\",\\\n",
    "    #\"landmark_PCAKurtosisFirstPC\", \"landmark_PCASkewnessFirstPC\"]\n",
    "\n",
    "def  extractMetaFeatures(dataset, file, classCol = None):\n",
    "    \n",
    "    \n",
    "    \n",
    "    t0 = time.time()\n",
    "    \n",
    "    #### 5. Number of Classes - DONE\n",
    "    if classCol == None:\n",
    "        target_variable_Index = dataset.shape[1] - 1\n",
    "    else:\n",
    "         target_variable_Index = dataset.columns.get_loc(classCol)\n",
    "        \n",
    "    target_variable = dataset.iloc[:, target_variable_Index]\n",
    "    dataset.drop(dataset.columns[target_variable_Index], axis=1, inplace = True)\n",
    "    \n",
    "    nr_classes = target_variable.nunique()\n",
    "    print(nr_classes)\n",
    "    t1 = time.time()\n",
    "    #print('1. Time spend:', t1 - t0)\n",
    "    #### Remove Missing Values\n",
    "    dataset.replace(to_replace = [\"? \",\"?\", \" ?\" \"-\" \" -\",\"- \", \" - \", \"#\", \" #\", \"# \",\" # \", \" \"], value = np.NAN, inplace = True)\n",
    "    dataset.dropna(axis = 1, how = 'all', inplace = True) # Drop Column if all of its values are missing\n",
    "\n",
    "    #### Remove ID columns or columns with always the same value\n",
    "    for col in dataset.columns:\n",
    "        feature = dataset[col].dropna()\n",
    "        numSyms = feature.nunique()\n",
    "        if col == 'id' or col == 'ID' or numSyms == 1 or (numSyms == dataset.shape[0] and feature.dtype != np.number):\n",
    "            dataset.drop(col, axis = 1, inplace = True)\n",
    "    \n",
    "    t0 = time.time()\n",
    "    #print('Preprocessing Time spent:', t0 - t1)\n",
    "    \n",
    "    ### 1.Number of Instances - DONE\n",
    "    nr_instances = dataset.shape[0]\n",
    "    t1 = time.time()\n",
    "    #print('1. Time spend:', t1 - t0)\n",
    "    \n",
    "    ### 2.Log number of Instances - DONE\n",
    "    log_nr_instances = np.log(nr_instances)\n",
    "    t2 = time.time()\n",
    "    #print('2. Time spend:', t2 - t1)\n",
    "    \n",
    "    #### 3.Number of Features - DONE\n",
    "    nr_features = dataset.shape[1]\n",
    "    t3 = time.time()\n",
    "    #print('3. Time spend:', t3 - t2)\n",
    "    \n",
    "    ### 4.Log Number of Features - DONE\n",
    "    log_nr_features = np.log(nr_features)\n",
    "    t4 = time.time()\n",
    "    #print('4. Time spend:', t4 - t3)\n",
    "    \n",
    "\n",
    "    ### 6. Number of Missing Values\n",
    "    ### 7. Ratio of Missing Values - DONE\n",
    "    missing_val = 0\n",
    "    missing_val = dataset.isnull().sum().sum() + dataset.isna().sum().sum()\n",
    "    \n",
    "    ratio_missing_val = missing_val / dataset.size\n",
    "    t7 = time.time()\n",
    "    #print('7. Time spend:', t7 - t6)\n",
    "    \n",
    "    ### 8. Number of Numerical Features - DONE\n",
    "    ### 9. Number of Categorical Features - DONE\n",
    "    numerical = []\n",
    "    categorical = dataset.select_dtypes(exclude=['number']).columns.values.tolist()\n",
    "    for col in dataset.columns:\n",
    "        if col not in categorical:\n",
    "            feature = dataset[col].dropna()\n",
    "            numSyms = feature.nunique()\n",
    "            if numSyms < log_nr_instances: #it should be considered as categorical if number of unique values < log number of instances\n",
    "                categorical.append(col)\n",
    "            else:\n",
    "                numerical.append(col)\n",
    "    \n",
    "    nr_numerical_features = len(numerical)\n",
    "    nr_categorical_features = len(categorical)\n",
    "    \n",
    "    t9 = time.time()\n",
    "    #print('9. Time spend:', t9 - t7)\n",
    "                \n",
    "    ### 10. Ratio of Categorical to Numerical Features - DONE\n",
    "    if(nr_numerical_features > 0):\n",
    "        ratio_num_cat = nr_categorical_features / nr_numerical_features\n",
    "    else:\n",
    "        ratio_num_cat = 9999999999\n",
    "    t10 = time.time()\n",
    "    #print('10. Time spend:', t10 - t9)\n",
    "    \n",
    "    ### 11. Class Entropy - DONE\n",
    "    prob_classes = []\n",
    "    class_entropy = 0\n",
    "    classes = target_variable.unique()\n",
    "    \n",
    "    for value in classes:\n",
    "        prob = (sum(target_variable==value) / len(target_variable))\n",
    "        \n",
    "        prob_classes.append(prob)\n",
    "        class_entropy = class_entropy - prob * np.log2(prob)\n",
    "        \n",
    "    ### 12. Maximum Class probability - DONE\n",
    "    max_prob = max(prob_classes)\n",
    "    \n",
    "    ### 13. Minimum Class probability - DONE\n",
    "    min_prob = min(prob_classes)\n",
    "    \n",
    "    ### 14. Mean Class probability - DONE\n",
    "    mean_prob = np.mean(prob_classes)\n",
    "    \n",
    "    ### 15. Standard Deviation of Class probability - DONE\n",
    "    std_dev = np.std(prob_classes)\n",
    "    \n",
    "    ### 16. Dataset Ratio - DONE\n",
    "    dataset_ratio = nr_features / nr_instances\n",
    "    \n",
    "    t11 = time.time()\n",
    "    #print('11. Time spend:', t11 - t10)\n",
    "    \n",
    "    ### Categorical Features Statistics\n",
    "    symbols=[]\n",
    "    if len(categorical) != 0:\n",
    "        for col in categorical:\n",
    "            feature = dataset[col].dropna()\n",
    "            symbols.append(feature.nunique())\n",
    "    \n",
    "    ### 17. Symbols Sum - DONE\n",
    "        symbols_sum = sum(symbols)\n",
    "        \n",
    "    ### 18. Symbols Mean - DONE\n",
    "        symbols_mean = np.mean(symbols)\n",
    "\n",
    "    ### 19. Symbols Standard Deviation - DONE\n",
    "        symbols_std_dev = np.std(symbols)\n",
    "        \n",
    "    else:\n",
    "        symbols_sum = 0\n",
    "        symbols_mean = 0\n",
    "        symbols_std_dev = 0\n",
    "    \n",
    "    t12 = time.time()\n",
    "    #print('12. Time spend:', t12 - t11)\n",
    "    \n",
    "    ### Numerical Features Statistics\n",
    "    skewness_values = np.zeros(len(numerical))\n",
    "    kurtosis_values = np.zeros(len(numerical))\n",
    "    \n",
    "    #print(dataset)\n",
    "    if len(numerical) != 0:\n",
    "        for coli in range(len(numerical)):\n",
    "            #print(numerical[coli])\n",
    "            feature = dataset[numerical[coli]].dropna()\n",
    "            #print('feat-AFTER:', feature)\n",
    "            skewness = skew(feature)\n",
    "            kurt = kurtosis(feature)\n",
    "            skewness_values[coli] = skewness\n",
    "            kurtosis_values[coli] = kurt\n",
    "    \n",
    "    ### 20. Skewness Minimum - DONE\n",
    "        skew_min = min(skewness_values)\n",
    "\n",
    "    ### 21. Skewness Maximum - DONE\n",
    "        skew_max = max(skewness_values)\n",
    "\n",
    "    ### 22. Skewness Mean - DONE\n",
    "        skew_mean = np.mean(skewness_values)\n",
    "\n",
    "    ### 23. Skewness Standard deviation - DONE\n",
    "        skew_std_dev = np.std(skewness_values)\n",
    "\n",
    "    ### 24. Kurtosis Minimum - DONE\n",
    "        kurtosis_min = min(kurtosis_values)\n",
    "\n",
    "    ### 25. Kurtosis Maximum - DONE\n",
    "        kurtosis_max = max(kurtosis_values)\n",
    "\n",
    "    ### 26. Kurtosis Mean - DONE\n",
    "        kurtosis_mean = np.mean(kurtosis_values)\n",
    "\n",
    "    ### 27. Kurtosis Standard Deviation - DONE\n",
    "        kurtosis_std_dev = np.std(kurtosis_values)\n",
    "    else:\n",
    "        skew_min = 0\n",
    "        skew_max = 0\n",
    "        skew_mean = 0\n",
    "        skew_std_dev = 0\n",
    "        kurtosis_min = 0\n",
    "        kurtosis_max = 0\n",
    "        kurtosis_mean = 0\n",
    "        kurtosis_std_dev = 0\n",
    "    \n",
    "    #t13 = time.time()\n",
    "    #print('13. Time spend:', t13 - t12)    \n",
    "    \n",
    "    #class_col=dataset.iloc[:,-1]\n",
    "    #dataset=pd.get_dummies(dataset.iloc[:,:-1])\n",
    "    #dataset[\"class\"]=class_col\n",
    "    \n",
    "        \n",
    "    y=target_variable\n",
    "    print(y.nunique())\n",
    "    \n",
    "    X = dataset\n",
    "    X = pd.get_dummies(X)\n",
    "    \n",
    "    le = preprocessing.LabelEncoder()\n",
    "    y=le.fit_transform(y.astype(str))\n",
    "    #landmark_lda = calculate_landmark_lda(X,y)\n",
    "   # landmark_nb = calculate_landmark_nb(X,y)\n",
    "    #landmark_dt = calculate_landmark_dt(X,y)\n",
    "    #landmark_dnl = calculate_landmark_dnl(X,y)\n",
    "    #landmark_rnl = calculate_landmark_rnl(X,y)\n",
    "    #landmark_k1nn = calculate_landmark_k1nn(X,y)\n",
    "    \n",
    "    #pca=calculate_pca(X,y)\n",
    "    #landmark_PCA95PercentVariance = calculate_PCAFractionOfComponentsFor95PercentVariance(X,y,pca)\n",
    "    #landmark_PCAKurtosisFirstPC = calculate_PCAKurtosisFirstPC(X,y,pca)\n",
    "    #landmark_PCASkewnessFirstPC = calculate_PCASkewnessFirstPC(X,y,pca)\n",
    "    \n",
    "    \n",
    "    meta_features=np.array([file, nr_instances,log_nr_instances,nr_features,\\\n",
    "    log_nr_features,nr_classes,nr_numerical_features,nr_categorical_features,ratio_num_cat,\\\n",
    "    class_entropy, missing_val, ratio_missing_val,max_prob,min_prob, mean_prob,\\\n",
    "    std_dev,dataset_ratio,symbols_sum,symbols_mean,symbols_std_dev,\\\n",
    "    skew_min,skew_max,skew_mean,skew_std_dev,kurtosis_min,kurtosis_max,kurtosis_mean,kurtosis_std_dev])\n",
    "    #landmark_lda,landmark_nb,landmark_dt,landmark_dnl,landmark_rnl,landmark_k1nn,\n",
    "    #landmark_PCA95PercentVariance, landmark_PCAKurtosisFirstPC,landmark_PCASkewnessFirstPC])\n",
    "    \n",
    "    \n",
    "    return  meta_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "file=\"server/uploads/blood.csv\"\n",
    "dataset = pd.read_csv(file, index_col=None, header=0)\n",
    "new_meta = extractMetaFeatures(dataset, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['server/uploads/blood.csv', '748', '6.617402977974478', '4',\n",
       "       '1.3862943611198906', '2', '4', '0', '0.0', '0.7916446298452327',\n",
       "       '0', '0.0', '0.7620320855614974', '0.23796791443850268', '0.5',\n",
       "       '0.2620320855614974', '0.0053475935828877', '0', '0', '0',\n",
       "       '0.7479465443244487', '3.2048221801543617', '2.2585703379392172',\n",
       "       '1.026961731837591', '-0.2520030108444278', '15.76221572558892',\n",
       "       '10.148276743801551', '6.555214709542027'], dtype='<U24')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      " /home/salijona/AutoMLMetaLearn/Datasets_all/mozilla4.csv\n",
      "2\n",
      "2000\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      " /home/salijona/AutoMLMetaLearn/Datasets_all/phpuZu33P.csv\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "meta_data=[]\n",
    "path ='/home/salijona/AutoMLMetaLearn/Datasets_all' \n",
    "allFiles = glob.glob(path + \"/*.csv\")\n",
    "counter = 0\n",
    "\n",
    "columns=[\"file_name\",\"nr_instances\", \"log_nr_instances\", \"nr_features\",\\\n",
    "    \"log_nr_features\", \"nr_classes\", \"nr_numerical_features\", \"nr_categorical_features\", \\\n",
    "    \"ratio_num_cat\", \"class_entropy\", \"missing_val\", \"ratio_missing_val\", \"max_prob\", \\\n",
    "    \"min_prob\", \"mean_prob\",\"std_dev\", \"dataset_ratio\", \"symbols_sum\", \"symbols_mean\", \\\n",
    "    \"symbols_std_dev\", \"skew_min\", \"skew_max\", \"skew_mean\", \"skew_std_dev\", \"kurtosis_min\",\\\n",
    "    \"kurtosis_max\", \"kurtosis_mean\", \"kurtosis_std_dev\"]\n",
    "    #\"landmark_lda\", \"landmark_nb\",\"landmark_dt\",\\\n",
    "    #\"landmark_dnl\",\"landmark_rnl\", \"landmark_k1nn\", \"landmark_PCAFractionOfComponentsFor95PercentVariance\",\\\n",
    "    #\"landmark_PCAKurtosisFirstPC\", \"landmark_PCASkewnessFirstPC\" ]\n",
    "\n",
    "meta=pd.DataFrame(columns=columns)\n",
    "meta.to_csv(\"MetaData_test.csv\",index=False, columns=columns)\n",
    "\n",
    "for file in allFiles:\n",
    "    #counter += 1\n",
    "    print('$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\\n', file)\n",
    "\n",
    "    dataset = pd.read_csv(file, index_col=None, header=0)\n",
    "    new_meta = extractMetaFeatures(dataset, file)\n",
    "    new_meta=pd.DataFrame([new_meta], columns=columns)\n",
    "\n",
    "    new_meta.to_csv(\"MetaData_test.csv\", mode=\"a\", header=False, index=False, columns=columns)\n",
    "\n",
    "#warnings.filter(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(meta_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete_Merged.csv           Untitled2.ipynb  digits_c.np.npy  reg.py\r\n",
      "Meta-featuresSelection.ipynb  Untitled3.ipynb  digits_x.np.npy  \u001b[0m\u001b[01;34mserver\u001b[0m/\r\n",
      "MetaData_test.csv             \u001b[01;34mauto-sklearn\u001b[0m/    digits_y.np.npy  test.py\r\n",
      "\u001b[01;34mSMAC3\u001b[0m/                        \u001b[01;34mautosk\u001b[0m/          \u001b[01;34mgeorge\u001b[0m/          \u001b[01;34mtest_serv\u001b[0m/\r\n",
      "Untitled.ipynb                boston.npy       \u001b[01;34mhypersk\u001b[0m/         \u001b[01;34mtmg\u001b[0m/\r\n",
      "Untitled1.ipynb               \u001b[01;34mdata\u001b[0m/            \u001b[01;34moutp\u001b[0m/            \u001b[01;34mtmp\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data=pd.read_csv(\"MetaData.csv\", header=0,index_col=None)\n",
    "meta_data=meta_data.drop(meta_data.columns[0], axis=1)\n",
    "\n",
    "meta_data=np.array(meta_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "copyMeta = meta_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function to remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reject_outliers(data, m=2):\n",
    "    return data[abs(data - np.mean(data)) < m * np.std(data)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histogram Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_features_names=[\"nr_instances\", \"log_nr_instances\", \"nr_features\",\\\n",
    "    \"log_nr_features\", \"nr_classes\", \"nr_numerical_features\", \"nr_categorical_features\", \\\n",
    "    \"ratio_num_cat\", \"class_entropy\", \"missing_val\", \"ratio_missing_val\", \"max_prob\", \\\n",
    "    \"min_prob\", \"mean_prob\", \"std_dev\", \"dataset_ratio\", \"symbols_sum\", \"symbols_mean\", \\\n",
    "    \"symbols_std_dev\", \"skew_min\", \"skew_max\", \"skew_mean\", \"skew_std_dev\", \"kurtosis_min\",\\\n",
    "    \"kurtosis_max\", \"kurtosis_mean\", \"kurtosis_std_dev\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nr_instances\n"
     ]
    }
   ],
   "source": [
    "print(meta_features_names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "Meta-Data Shape: (200, 3)\n",
      "Length of Meta Features Names: 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fed01f96358>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.rcParams.update({'font.size': 500})\n",
    "\n",
    "meta_data = copyMeta.copy()\n",
    "print(type(meta_data))\n",
    "def histogram(meta_data,meta_features_names):\n",
    "    plt.rcParams.update({'font.size': 20})\n",
    "    plt.rcParams['figure.figsize'] = (20, 40)\n",
    "    j=0\n",
    "    print(\"Meta-Data Shape:\", meta_data.shape)\n",
    "    print(\"Length of Meta Features Names:\", len(meta_features_names))\n",
    "    for i in meta_data.T:\n",
    "        text = meta_features_names[j]\n",
    "        #if j == 1 or j == 3:\n",
    "            #j += 1\n",
    "            #continue\n",
    "            \n",
    "        ax = plt.subplot(9,3,1+j)\n",
    "        plt.xscale(\"log\")\n",
    "\n",
    "        plt.title('{}'.format(text))\n",
    "        \n",
    "        i = reject_outliers(i, 2)\n",
    "        mini = min(i)\n",
    "        maxi = max(i)    \n",
    "        \n",
    "        if mini <=  0:\n",
    "            i -= (mini-1)\n",
    "        \n",
    "        #print('feature processing now: ', text, ' --- mini:', mini, ' --- maxi:', maxi, '===i===', j)\n",
    "        plt.hist(i, bins = np.logspace(np.log10(min(i)), np.log10(max(i)), 10))\n",
    "\n",
    "        j=j+1\n",
    "    plt.savefig(\"All-Datasets-1.png\")\n",
    "    plt.show()\n",
    "b = [0,2,4]\n",
    "#b=[5,15,18]\n",
    "#b=[19,20,22]\n",
    "#b=[23,25,12]\n",
    "c = [ meta_features_names[i] for i in b]\n",
    "histogram(meta_data[:,b],c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heat Map Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.54\n"
     ]
    }
   ],
   "source": [
    "binary=np.sum(meta_data[:,4]==2)\n",
    "print(binary/200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (100, 40)\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(meta_data.T)\n",
    "\n",
    "dataset_info=np.arange(1, 20, 1, dtype=int)\n",
    "\n",
    "# We want to show all ticks...\n",
    "ax.set_xticks(np.arange(len(dataset_info)))\n",
    "ax.set_yticks(np.arange(len(meta_features_names)))\n",
    "# ... and label them with the respective list entries\n",
    "ax.set_xticklabels(dataset_info)\n",
    "ax.set_yticklabels(meta_features_names)\n",
    "\n",
    "# Rotate the tick labels and set their alignment.\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "         rotation_mode=\"anchor\")\n",
    "\n",
    "# Loop over data dimensions and create text annotations.\n",
    "for i in range(len(meta_features_names)):\n",
    "    for j in range(len(dataset_info)):\n",
    "        text = ax.text(j, i, int(meta_data[j, i]), ha=\"center\", va=\"center\", color=\"w\")\n",
    "\n",
    "ax.set_title(\"\")\n",
    "#fig.tight_layout()\n",
    "plt.savefig(\"heatmap.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
